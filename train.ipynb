{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbPsyfhNV7vI"
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
    "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
    "import kagglehub\n",
    "kagglehub.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fcgTMFeiV7vN"
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "\n",
    "bajrangikumarmishra_warehouse_dataset_path = kagglehub.dataset_download('bajrangikumarmishra/warehouse-dataset')\n",
    "bajrangikumarmishra_sathat_dataset_path = kagglehub.dataset_download('bajrangikumarmishra/sathat-dataset')\n",
    "bajrangikumarmishra_anamolies_detection_path = kagglehub.dataset_download('bajrangikumarmishra/anamolies-detection')\n",
    "bajrangikumarmishra_rackfall_dataset_path = kagglehub.dataset_download('bajrangikumarmishra/rackfall-dataset')\n",
    "bajrangikumarmishra_fight_dataset_path = kagglehub.dataset_download('bajrangikumarmishra/fight-dataset')\n",
    "bajrangikumarmishra_mangodb_idk_path = kagglehub.dataset_download('bajrangikumarmishra/mangodb-idk')\n",
    "\n",
    "print('Data source import complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "k149c4AUV7vP",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-16T00:13:05.425042Z",
     "iopub.status.busy": "2024-11-16T00:13:05.424628Z",
     "iopub.status.idle": "2024-11-16T00:15:03.969977Z",
     "shell.execute_reply": "2024-11-16T00:15:03.969056Z",
     "shell.execute_reply.started": "2024-11-16T00:13:05.425005Z"
    },
    "id": "h-y_rU9XV7vP",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Function to parse YOLO labels from the label file\n",
    "def parse_labels_from_file(file_path):\n",
    "    labels = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            label_parts = line.strip().split()\n",
    "            if len(label_parts) == 5:\n",
    "                class_id, x, y, w, h = map(float, label_parts)\n",
    "                labels.append((int(class_id), x, y, w, h))\n",
    "    return labels\n",
    "\n",
    "# Convert YOLO format to pixel coordinates\n",
    "def yolo_to_pixels(image_width, image_height, box):\n",
    "    x, y, w, h = box\n",
    "    xmin = int((x - w / 2) * image_width)\n",
    "    xmax = int((x + w / 2) * image_width)\n",
    "    ymin = int((y - h / 2) * image_height)\n",
    "    ymax = int((y + h / 2) * image_height)\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "# Detect anomalies based on custom criteria\n",
    "def detect_anomalies(labels, image_height, image_width):\n",
    "    anomalies = []\n",
    "    for label in labels:\n",
    "        class_id, x, y, w, h = label\n",
    "        _, ymin, _, ymax = yolo_to_pixels(image_width, image_height, (x, y, w, h))\n",
    "\n",
    "        # Custom anomaly criterion: Object near the bottom of the image\n",
    "        if ymax > 0.85 * image_height:  # Objects in the bottom 15% of the image\n",
    "            anomalies.append((class_id, x, y, w, h))\n",
    "    return anomalies\n",
    "\n",
    "# Display the image with bounding boxes and detected anomalies\n",
    "def display_image_with_labels(image_path, labels, is_anomalies=False):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "        return\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    # Detect anomalies if required\n",
    "    anomalies = detect_anomalies(labels, image_height, image_width) if is_anomalies else []\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    ax.imshow(image_rgb)\n",
    "\n",
    "    box_count = 0  # Initialize box count\n",
    "\n",
    "    # Plot each label\n",
    "    for label in labels:\n",
    "        class_id, x, y, w, h = label\n",
    "        xmin, ymin, xmax, ymax = yolo_to_pixels(image_width, image_height, (x, y, w, h))\n",
    "        color = 'r' if (class_id, x, y, w, h) in anomalies else 'g'\n",
    "\n",
    "        # Draw bounding box\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=2, edgecolor=color, facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Add text\n",
    "        ax.text(xmin, ymin - 10, f\"Class {class_id}\", fontsize=8, color='b')\n",
    "        if (class_id, x, y, w, h) in anomalies:\n",
    "            ax.text(xmin, ymax + 10, 'Object Fallen', fontsize=10, color='r')\n",
    "\n",
    "        box_count += 1\n",
    "\n",
    "    # Display information\n",
    "    if anomalies:\n",
    "        ax.text(10, 20, f\"Total Boxes: {box_count}, Anomalies: {len(anomalies)}\", fontsize=12, color='yellow', bbox=dict(facecolor='black', alpha=0.5))\n",
    "    else:\n",
    "        ax.text(10, 20, f\"Total Boxes: {box_count}\\nNo Anomalies Detected\", fontsize=12, color='yellow', bbox=dict(facecolor='black', alpha=0.5))\n",
    "\n",
    "    # Plot settings\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Paths for datasets\n",
    "normal_img_path = '/kaggle/input/sathat-dataset/train/images'  # Update this path\n",
    "normal_labels_path = '/kaggle/input/sathat-dataset/train/labels'  # Update this path\n",
    "anomalies_img_path = '/kaggle/input/anamolies-detection/train/images'  # Update this path\n",
    "anomalies_labels_path = '/kaggle/input/anamolies-detection/train/labels'  # Update this path\n",
    "# Process and display normal images\n",
    "print(\"Processing Normal Images:\")\n",
    "for image_name in os.listdir(normal_img_path):\n",
    "    image_path = os.path.join(normal_img_path, image_name)\n",
    "    label_path = os.path.join(normal_labels_path, f\"{os.path.splitext(image_name)[0]}.txt\")\n",
    "    if os.path.exists(label_path):\n",
    "        labels = parse_labels_from_file(label_path)\n",
    "        display_image_with_labels(image_path, labels, is_anomalies=False)\n",
    "\n",
    "# Process and display anomaly images\n",
    "print(\"Processing Anomalies Dataset:\")\n",
    "for image_name in os.listdir(anomalies_img_path):\n",
    "    image_path = os.path.join(anomalies_img_path, image_name)\n",
    "    label_path = os.path.join(anomalies_labels_path, f\"{os.path.splitext(image_name)[0]}.txt\")\n",
    "    if os.path.exists(label_path):\n",
    "        labels = parse_labels_from_file(label_path)\n",
    "        display_image_with_labels(image_path, labels, is_anomalies=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:24:33.160151Z",
     "iopub.status.busy": "2024-11-15T23:24:33.159776Z",
     "iopub.status.idle": "2024-11-15T23:24:44.309443Z",
     "shell.execute_reply": "2024-11-15T23:24:44.308561Z",
     "shell.execute_reply.started": "2024-11-15T23:24:33.160113Z"
    },
    "id": "CyjMOayLV7vQ",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Function to parse YOLO labels from the label file\n",
    "def parse_labels_from_file(file_path):\n",
    "    labels = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            label_parts = line.strip().split()\n",
    "            if len(label_parts) == 5:\n",
    "                class_id, x, y, w, h = map(float, label_parts)\n",
    "                labels.append((int(class_id), x, y, w, h))\n",
    "    return labels\n",
    "\n",
    "# Convert YOLO format to pixel coordinates\n",
    "def yolo_to_pixels(image_width, image_height, box):\n",
    "    x, y, w, h = box\n",
    "    xmin = max(0, int((x - w / 2) * image_width))\n",
    "    xmax = min(image_width, int((x + w / 2) * image_width))\n",
    "    ymin = max(0, int((y - h / 2) * image_height))\n",
    "    ymax = min(image_height, int((y + h / 2) * image_height))\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "# Detect anomalies based on criteria, including rack fall, fight, and item fall detection\n",
    "def detect_anomalies(labels, image_height, image_width, detect_type=None):\n",
    "    anomalies = []\n",
    "    for label in labels:\n",
    "        class_id, x, y, w, h = label\n",
    "        xmin, ymin, xmax, ymax = yolo_to_pixels(image_width, image_height, (x, y, w, h))\n",
    "\n",
    "        # Custom criteria for detecting anomalies\n",
    "        box_height = ymax - ymin\n",
    "        box_width = xmax - xmin\n",
    "        area = box_width * box_height\n",
    "        is_near_bottom = ymax > 0.8 * image_height\n",
    "        is_small = area < 0.02 * image_width * image_height\n",
    "        is_large = area > 0.5 * image_width * image_height\n",
    "\n",
    "        # Determine anomaly type based on the dataset\n",
    "        is_rack_fall = detect_type == \"rack_fall\"\n",
    "        is_fight = detect_type == \"fight\"\n",
    "        is_item_fall = detect_type == \"anomalies\" and (is_near_bottom or is_small or is_large)\n",
    "\n",
    "        if is_rack_fall or is_fight or is_item_fall:\n",
    "            anomalies.append((class_id, x, y, w, h))\n",
    "            if is_rack_fall:\n",
    "                print(f\"Rack Fall detected: Class {class_id} at position ({x:.2f}, {y:.2f}) with area {area:.2f}\")\n",
    "            elif is_fight:\n",
    "                print(f\"Fight detected: Class {class_id} at position ({x:.2f}, {y:.2f}) with area {area:.2f}\")\n",
    "            elif is_item_fall:\n",
    "                print(f\"Item Fall detected: Class {class_id} at position ({x:.2f}, {y:.2f}) with area {area:.2f}\")\n",
    "\n",
    "    return anomalies\n",
    "\n",
    "# Display the image with bounding boxes and detected anomalies\n",
    "def display_image_with_labels(image_path, labels, detect_type=None):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {image_path}\")\n",
    "        return\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    # Detect anomalies based on the dataset type\n",
    "    anomalies = detect_anomalies(labels, image_height, image_width, detect_type=detect_type)\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    ax.imshow(image_rgb)\n",
    "\n",
    "    box_count = 0  # Initialize box count\n",
    "\n",
    "    # Plot each label\n",
    "    for label in labels:\n",
    "        class_id, x, y, w, h = label\n",
    "        xmin, ymin, xmax, ymax = yolo_to_pixels(image_width, image_height, (x, y, w, h))\n",
    "        color = 'r' if (class_id, x, y, w, h) in anomalies else 'g'\n",
    "        label_text = \"\"\n",
    "\n",
    "        # Label anomalies based on the type\n",
    "        if (class_id, x, y, w, h) in anomalies:\n",
    "            if detect_type == \"rack_fall\":\n",
    "                label_text = \"Rack Fall\"\n",
    "            elif detect_type == \"fight\":\n",
    "                label_text = \"Fight\"\n",
    "            elif detect_type == \"anomalies\":\n",
    "                label_text = \"Item Fall\"\n",
    "            ax.text(xmin, ymax + 10, label_text, fontsize=10, color='r')\n",
    "\n",
    "        # Draw bounding box\n",
    "        rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, linewidth=2, edgecolor=color, facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Add class text\n",
    "        ax.text(xmin, ymin - 10, f\"Class {class_id}\", fontsize=8, color='b')\n",
    "\n",
    "        box_count += 1\n",
    "\n",
    "    # Display information\n",
    "    if anomalies:\n",
    "        ax.text(10, 20, f\"Total Boxes: {box_count}, Anomalies: {len(anomalies)}\", fontsize=12, color='yellow', bbox=dict(facecolor='black', alpha=0.5))\n",
    "    else:\n",
    "        ax.text(10, 20, f\"Total Boxes: {box_count}\\nNo Anomalies Detected\", fontsize=12, color='yellow', bbox=dict(facecolor='black', alpha=0.5))\n",
    "\n",
    "    # Plot settings\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Limit the output to a certain number of images per category\n",
    "def process_and_display_images(image_path, labels_path, detect_type=None, max_images=10):\n",
    "    count = 0\n",
    "    for image_name in sorted(os.listdir(image_path)):\n",
    "        if count >= max_images:\n",
    "            break\n",
    "        image_file = os.path.join(image_path, image_name)\n",
    "        label_file = os.path.join(labels_path, f\"{os.path.splitext(image_name)[0]}.txt\")\n",
    "        if os.path.exists(label_file):\n",
    "            labels = parse_labels_from_file(label_file)\n",
    "            print(f\"Processing {image_file} with labels {label_file}\")\n",
    "            display_image_with_labels(image_file, labels, detect_type=detect_type)\n",
    "            count += 1\n",
    "        else:\n",
    "            print(f\"No label file found for {image_name}\")\n",
    "\n",
    "# Paths for datasets\n",
    "normal_img_path = '/kaggle/input/sathat-dataset/train/images'  # Update this path\n",
    "normal_labels_path = '/kaggle/input/sathat-dataset/train/labels'  # Update this path\n",
    "anomalies_img_path = '/kaggle/input/anamolies-detection/train/images'  # Update this path\n",
    "anomalies_labels_path = '/kaggle/input/anamolies-detection/train/labels'  # Update this path\n",
    "rack_fall_img_path = '/kaggle/input/rackfall-dataset/train/images'  # Update this path\n",
    "rack_fall_labels_path = '/kaggle/input/rackfall-dataset/train/labels'  # Update this path\n",
    "fight_img_path = '/kaggle/input/fight-dataset/train/images'  # Update this path\n",
    "fight_labels_path = '/kaggle/input/fight-dataset/train/labels'  # Update this path\n",
    "\n",
    "# Process and display images\n",
    "print(\"Processing Normal Images:\")\n",
    "process_and_display_images(normal_img_path, normal_labels_path, detect_type=None, max_images=10)\n",
    "\n",
    "print(\"Processing Anomalies Dataset for Item Fall:\")\n",
    "process_and_display_images(anomalies_img_path, anomalies_labels_path, detect_type=\"anomalies\", max_images=10)\n",
    "\n",
    "print(\"Processing Rack Fall Dataset:\")\n",
    "process_and_display_images(rack_fall_img_path, rack_fall_labels_path, detect_type=\"rack_fall\", max_images=10)\n",
    "\n",
    "print(\"Processing Fight Detection Dataset:\")\n",
    "process_and_display_images(fight_img_path, fight_labels_path, detect_type=\"fight\", max_images=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:24:44.312283Z",
     "iopub.status.busy": "2024-11-15T23:24:44.311737Z",
     "iopub.status.idle": "2024-11-15T23:24:44.364636Z",
     "shell.execute_reply": "2024-11-15T23:24:44.363551Z",
     "shell.execute_reply.started": "2024-11-15T23:24:44.312239Z"
    },
    "id": "9FF692edV7vR",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Function to parse YOLO labels from the label file\n",
    "def parse_labels_from_file(file_path):\n",
    "    labels = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            label_parts = line.strip().split()\n",
    "            if len(label_parts) == 5:\n",
    "                class_id, x, y, w, h = map(float, label_parts)\n",
    "                labels.append((int(class_id), x, y, w, h))\n",
    "    return labels\n",
    "\n",
    "# Convert YOLO format to pixel coordinates\n",
    "def yolo_to_pixels(image_width, image_height, box):\n",
    "    x, y, w, h = box\n",
    "    xmin = max(0, int((x - w / 2) * image_width))\n",
    "    xmax = min(image_width, int((x + w / 2) * image_width))\n",
    "    ymin = max(0, int((y - h / 2) * image_height))\n",
    "    ymax = min(image_height, int((y + h / 2) * image_height))\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "# Detect anomalies based on criteria and return appropriate indicators\n",
    "def detect_anomalies(labels, detect_fight=False):\n",
    "    fight_detected, itemfall_detected, rackfall_detected = \"\", \"\", \"\"\n",
    "    total_objects = len(labels)\n",
    "\n",
    "    for label in labels:\n",
    "        class_id, x, y, w, h = label\n",
    "\n",
    "        is_rack_fall = class_id == 1  # Assume class_id 1 is used for rack fall detection\n",
    "        is_fight = class_id == 2 if detect_fight else False  # Assume class_id 2 is for fight detection\n",
    "        is_item_fall = class_id == 3  # Assume class_id 3 is for item fall detection\n",
    "\n",
    "        if is_rack_fall:\n",
    "            rackfall_detected = 1\n",
    "        elif is_fight:\n",
    "            fight_detected = 1\n",
    "        elif is_item_fall:\n",
    "            itemfall_detected = 1\n",
    "\n",
    "    return fight_detected, itemfall_detected, rackfall_detected, total_objects\n",
    "\n",
    "# Write results to a single CSV file\n",
    "def save_results_to_csv(results, csv_filename=\"consolidated_results.csv\"):\n",
    "    # Specify CSV headers\n",
    "    headers = [\"Dataset\", \"Image\", \"Fight\", \"ItemFall\", \"RackFall\", \"Total_Objects\"]\n",
    "\n",
    "    # Write results to CSV\n",
    "    with open(csv_filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)\n",
    "        writer.writerows(results)\n",
    "    print(f\"Results saved to {csv_filename}\")\n",
    "\n",
    "# Process images and store results in a single CSV\n",
    "def process_images(image_path, labels_path, dataset_name, detect_fight=False, max_images=10):\n",
    "    results = []\n",
    "    count = 0\n",
    "    for image_name in sorted(os.listdir(image_path)):\n",
    "        if count >= max_images:\n",
    "            break\n",
    "        image_file = os.path.join(image_path, image_name)\n",
    "        label_file = os.path.join(labels_path, f\"{os.path.splitext(image_name)[0]}.txt\")\n",
    "        if os.path.exists(label_file):\n",
    "            labels = parse_labels_from_file(label_file)\n",
    "            print(f\"Processing {image_file} with labels {label_file}\")\n",
    "            fight_detected, itemfall_detected, rackfall_detected, total_objects = detect_anomalies(\n",
    "                labels, detect_fight=detect_fight\n",
    "            )\n",
    "            results.append([dataset_name, image_name, fight_detected, itemfall_detected, rackfall_detected, total_objects])\n",
    "            count += 1\n",
    "        else:\n",
    "            print(f\"No label file found for {image_name}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Paths for datasets\n",
    "normal_img_path = '/kaggle/input/sathat-dataset/train/images'  # Update this path\n",
    "normal_labels_path = '/kaggle/input/sathat-dataset/train/labels'  # Update this path\n",
    "anomalies_img_path = '/kaggle/input/anamolies-detection/train/images'  # Update this path\n",
    "anomalies_labels_path = '/kaggle/input/anamolies-detection/train/labels'  # Update this path\n",
    "rack_fall_img_path = '/kaggle/input/rackfall-dataset/train/images'  # Update this path\n",
    "rack_fall_labels_path = '/kaggle/input/rackfall-dataset/train/labels'  # Update this path\n",
    "fight_img_path = '/kaggle/input/fight-dataset/train/images'  # Update this path\n",
    "fight_labels_path = '/kaggle/input/fight-dataset/train/labels'  # Update this path\n",
    "\n",
    "# Collect results from all datasets\n",
    "all_results = []\n",
    "all_results.extend(process_images(normal_img_path, normal_labels_path, \"Normal\", detect_fight=False, max_images=10))\n",
    "all_results.extend(process_images(anomalies_img_path, anomalies_labels_path, \"Anomalies\", detect_fight=False, max_images=10))\n",
    "all_results.extend(process_images(rack_fall_img_path, rack_fall_labels_path, \"Rack Fall\", detect_fight=False, max_images=10))\n",
    "all_results.extend(process_images(fight_img_path, fight_labels_path, \"Fight Detection\", detect_fight=True, max_images=10))\n",
    "\n",
    "# Save all results to a single CSV file\n",
    "save_results_to_csv(all_results, csv_filename=\"consolidated_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:24:44.366755Z",
     "iopub.status.busy": "2024-11-15T23:24:44.366196Z",
     "iopub.status.idle": "2024-11-15T23:24:44.401059Z",
     "shell.execute_reply": "2024-11-15T23:24:44.400173Z",
     "shell.execute_reply.started": "2024-11-15T23:24:44.366708Z"
    },
    "id": "InO6dFN9V7vT",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Function to parse YOLO labels from the label file\n",
    "def parse_labels_from_file(file_path):\n",
    "    labels = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            label_parts = line.strip().split()\n",
    "            if len(label_parts) == 5:\n",
    "                class_id, x, y, w, h = map(float, label_parts)\n",
    "                labels.append((int(class_id), x, y, w, h))\n",
    "    return labels\n",
    "\n",
    "# Detect anomalies based on dataset type\n",
    "def detect_anomalies(labels, dataset_type):\n",
    "    fight_detected, itemfall_detected, rackfall_detected = None, None, None\n",
    "    total_objects = len(labels)\n",
    "\n",
    "    if dataset_type == \"Normal\":\n",
    "        # Only count total objects, other columns remain None\n",
    "        pass\n",
    "    elif dataset_type == \"Fight Detection\":\n",
    "        for label in labels:\n",
    "            if label[0] == 2:  # Class ID 2 for fight\n",
    "                fight_detected = 1\n",
    "                break\n",
    "    elif dataset_type == \"Anomalies\":\n",
    "        for label in labels:\n",
    "            if label[0] == 3:  # Class ID 3 for item fall\n",
    "                itemfall_detected = 1\n",
    "                break\n",
    "    elif dataset_type == \"Rack Fall\":\n",
    "        for label in labels:\n",
    "            if label[0] == 1:  # Class ID 1 for rack fall\n",
    "                rackfall_detected = 1\n",
    "                break\n",
    "\n",
    "    return fight_detected, itemfall_detected, rackfall_detected, total_objects\n",
    "\n",
    "# Write results to a single CSV file\n",
    "def save_results_to_csv(results, csv_filename=\"consolidated_results.csv\"):\n",
    "    headers = [\"Dataset\", \"Image\", \"Fight\", \"ItemFall\", \"RackFall\", \"Total_Objects\"]\n",
    "\n",
    "    with open(csv_filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)\n",
    "        writer.writerows(results)\n",
    "    print(f\"Results saved to {csv_filename}\")\n",
    "\n",
    "# Process images and store results in a single CSV\n",
    "def process_images(image_path, labels_path, dataset_name, max_images=10):\n",
    "    results = []\n",
    "    count = 0\n",
    "    for image_name in sorted(os.listdir(image_path)):\n",
    "        if count >= max_images:\n",
    "            break\n",
    "        image_file = os.path.join(image_path, image_name)\n",
    "        label_file = os.path.join(labels_path, f\"{os.path.splitext(image_name)[0]}.txt\")\n",
    "        if os.path.exists(label_file):\n",
    "            labels = parse_labels_from_file(label_file)\n",
    "            print(f\"Processing {image_file} with labels {label_file}\")\n",
    "            fight_detected, itemfall_detected, rackfall_detected, total_objects = detect_anomalies(\n",
    "                labels, dataset_name\n",
    "            )\n",
    "            results.append([dataset_name, image_name, fight_detected, itemfall_detected, rackfall_detected, total_objects])\n",
    "            count += 1\n",
    "        else:\n",
    "            print(f\"No label file found for {image_name}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Paths for datasets\n",
    "normal_img_path = '/kaggle/input/sathat-dataset/train/images'\n",
    "normal_labels_path = '/kaggle/input/sathat-dataset/train/labels'\n",
    "anomalies_img_path = '/kaggle/input/anamolies-detection/train/images'\n",
    "anomalies_labels_path = '/kaggle/input/anamolies-detection/train/labels'\n",
    "rack_fall_img_path = '/kaggle/input/rackfall-dataset/train/images'\n",
    "rack_fall_labels_path = '/kaggle/input/rackfall-dataset/train/labels'\n",
    "fight_img_path = '/kaggle/input/fight-dataset/train/images'\n",
    "fight_labels_path = '/kaggle/input/fight-dataset/train/labels'\n",
    "\n",
    "# Collect results from all datasets\n",
    "all_results = []\n",
    "all_results.extend(process_images(normal_img_path, normal_labels_path, \"Normal\", max_images=10))\n",
    "all_results.extend(process_images(anomalies_img_path, anomalies_labels_path, \"Anomalies\", max_images=10))\n",
    "all_results.extend(process_images(rack_fall_img_path, rack_fall_labels_path, \"Rack Fall\", max_images=10))\n",
    "all_results.extend(process_images(fight_img_path, fight_labels_path, \"Fight Detection\", max_images=10))\n",
    "\n",
    "# Save all results to a single CSV file\n",
    "save_results_to_csv(all_results, csv_filename=\"consolidated_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:24:44.402994Z",
     "iopub.status.busy": "2024-11-15T23:24:44.402712Z",
     "iopub.status.idle": "2024-11-15T23:24:44.412878Z",
     "shell.execute_reply": "2024-11-15T23:24:44.411933Z",
     "shell.execute_reply.started": "2024-11-15T23:24:44.402963Z"
    },
    "id": "5WA3txcCV7vV",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('consolidated_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:24:44.414252Z",
     "iopub.status.busy": "2024-11-15T23:24:44.413976Z",
     "iopub.status.idle": "2024-11-15T23:24:44.438443Z",
     "shell.execute_reply": "2024-11-15T23:24:44.437519Z",
     "shell.execute_reply.started": "2024-11-15T23:24:44.414222Z"
    },
    "id": "PnFINF2mV7vV",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to process data for each dataset type\n",
    "def process_data(df):\n",
    "    # Initialize new columns with NaN\n",
    "    df['Fight'] = np.nan\n",
    "    df['ItemFall'] = np.nan\n",
    "    df['RackFall'] = np.nan\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        dataset_type = row['Dataset']\n",
    "        if dataset_type == 'Normal':\n",
    "            # For Normal: only Total_Objects is populated\n",
    "            continue\n",
    "        elif dataset_type == 'Fight Detection':\n",
    "            # For Fight Detection: populate Fight, leave others NaN\n",
    "            df.at[index, 'Fight'] = 1\n",
    "        elif dataset_type == 'Anomalies':\n",
    "            # For Anomalies: populate ItemFall, leave others NaN\n",
    "            df.at[index, 'ItemFall'] = 1\n",
    "        elif dataset_type == 'Rack Fall':\n",
    "            # For Rack Fall: populate RackFall, leave others NaN\n",
    "            df.at[index, 'RackFall'] = 1\n",
    "\n",
    "    return df\n",
    "\n",
    "# Process the data\n",
    "processed_df = process_data(df)\n",
    "\n",
    "# Display the processed DataFrame\n",
    "print(processed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:26:56.103873Z",
     "iopub.status.busy": "2024-11-15T23:26:56.103384Z",
     "iopub.status.idle": "2024-11-15T23:26:56.126887Z",
     "shell.execute_reply": "2024-11-15T23:26:56.126106Z",
     "shell.execute_reply.started": "2024-11-15T23:26:56.103833Z"
    },
    "id": "R25b5eYzV7vW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "processed_df.to_csv('processed_dataset.csv', index=False)\n",
    "\n",
    "# Save to Excel\n",
    "processed_df.to_excel('processed_dataset.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:24:44.838463Z",
     "iopub.status.busy": "2024-11-15T23:24:44.837935Z",
     "iopub.status.idle": "2024-11-15T23:24:44.864297Z",
     "shell.execute_reply": "2024-11-15T23:24:44.863355Z",
     "shell.execute_reply.started": "2024-11-15T23:24:44.838415Z"
    },
    "id": "-JcD8kwsV7vX",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:32:26.755548Z",
     "iopub.status.busy": "2024-11-15T23:32:26.755188Z",
     "iopub.status.idle": "2024-11-15T23:32:26.78158Z",
     "shell.execute_reply": "2024-11-15T23:32:26.780512Z",
     "shell.execute_reply.started": "2024-11-15T23:32:26.755513Z"
    },
    "id": "Ygx1TLlTV7vX",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Add a column for rack number\n",
    "df[\"Rack_Number\"] = df[\"Image\"].rank(method=\"dense\").astype(int)\n",
    "\n",
    "# Replace NaN with 0\n",
    "df.fillna(0, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-15T23:32:53.108331Z",
     "iopub.status.busy": "2024-11-15T23:32:53.107332Z",
     "iopub.status.idle": "2024-11-15T23:32:53.132684Z",
     "shell.execute_reply": "2024-11-15T23:32:53.131712Z",
     "shell.execute_reply.started": "2024-11-15T23:32:53.108285Z"
    },
    "id": "JMd5NvyZV7vX",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "processed_df.to_csv('processed_dataset1.csv', index=False)\n",
    "\n",
    "# Save to Excel\n",
    "processed_df.to_excel('processed_dataset1.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ws4ghDRV7vY",
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Mind_benders",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6095301,
     "sourceId": 9918275,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6095391,
     "sourceId": 9918384,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6095525,
     "sourceId": 9918562,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6095798,
     "sourceId": 9918904,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6095852,
     "sourceId": 9918987,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6096001,
     "sourceId": 9919188,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
